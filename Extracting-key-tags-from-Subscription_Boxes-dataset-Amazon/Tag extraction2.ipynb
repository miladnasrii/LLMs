{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OkwPoUnFDpi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to divide the text into sentences"
      ],
      "metadata": {
        "id": "rwMo0Kk1CDsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences(string):\n",
        "    string = re.sub('[:,?!\\n]', '.', string)\n",
        "    sentences = [sent.strip() for sent in string.split('.') if sent.strip() != '']\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "sXJGnil3FE80"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to count attributes and names"
      ],
      "metadata": {
        "id": "43-YIdWaCKQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_attr(string):\n",
        "    subj_num = 0\n",
        "    noun_num = 0\n",
        "    adj_num = 0\n",
        "    nouns = []\n",
        "    adjs = []\n",
        "    words = string.lower().split()\n",
        "    w_t_list = nltk.pos_tag(words)\n",
        "    for (w, t) in w_t_list:\n",
        "        if w in subj_words:\n",
        "            subj_num += 1\n",
        "        if t in noun_taggers:\n",
        "            noun_num += 1\n",
        "            nouns.append(w)\n",
        "        if t in adj_taggers:\n",
        "            adj_num += 1\n",
        "            adjs.append(w)\n",
        "    return len(words), subj_num, noun_num, adj_num, nouns, adjs"
      ],
      "metadata": {
        "id": "preC_mIDFNGa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_words = ['i', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves']\n",
        "noun_taggers = ['NN', 'NNP', 'NNPS', 'NNS']\n",
        "adj_taggers = ['JJ', 'JJR', 'JJS']"
      ],
      "metadata": {
        "id": "wCWe7Ue5FjHP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the json file"
      ],
      "metadata": {
        "id": "HIceh6UeCSvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Subscription_Boxes.jsonl'"
      ],
      "metadata": {
        "id": "KfxrrG79FoCe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting the text of comments"
      ],
      "metadata": {
        "id": "fNf2NdSJCbRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        data = json.loads(line)\n",
        "        reviews.append(data['text'])"
      ],
      "metadata": {
        "id": "za9XlsLmFrRj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing comments"
      ],
      "metadata": {
        "id": "1HnT55ctCkyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, review in enumerate(reviews):\n",
        "    exps = get_sentences(review)\n",
        "    for exp in exps:\n",
        "        word_n, subj_n, noun_n, adj_n, nouns, adjs = get_sentence_attr(exp)\n",
        "        print(f\"Review Index: {idx}\")\n",
        "        print(f\"Sentence: {exp}\")\n",
        "        print(f\"Word Count: {word_n}, Subject Count: {subj_n}\")\n",
        "        print(f\"Nouns ({noun_n}): {nouns}\")\n",
        "        print(f\"Adjectives ({adj_n}): {adjs}\")\n",
        "        print('-' * 50)"
      ],
      "metadata": {
        "id": "e5imFYI_Ft6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}