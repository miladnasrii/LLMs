# -*- coding: utf-8 -*-
"""code_assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IsYYKLVXPLR-LkvAmJ2i9X0GkXYHcNUs
"""

!pip install transformers torch gradio

from transformers import AutoModelForCausalLM, AutoTokenizer
import gradio as gr

model_name = "EleutherAI/gpt-neo-1.3B"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

def generate_code(prompt, max_length=200):
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(
        **inputs,
        max_length=max_length,
        temperature=0.7,
        top_p=0.95,
        do_sample=True
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def assistant(prompt):
    return generate_code(prompt)

iface = gr.Interface(fn=assistant, inputs="text", outputs="code", title="Python Coding Assistant")
iface.launch()