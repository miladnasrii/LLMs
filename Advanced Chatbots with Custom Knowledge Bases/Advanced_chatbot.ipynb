{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SASwlJS-SdWp"
   },
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers langchain faiss-cpu pypdf langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXKc331jSi3h"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFFw4MsKSjQs"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZeqOjyKSnwi"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def create_vector_database(text, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    sentences = text.split(\". \")\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    embeddings = model.encode(sentences, show_progress_bar=True)\n",
    "\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZi4_oFQSpCY"
   },
   "outputs": [],
   "source": [
    "def retrieve_answer(query, index, sentences, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    D, I = index.search(query_embedding, k=5)\n",
    "    results = [sentences[i] for i in I[0]]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUOEBUvSSqVQ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "def generate_answer(context, query, model_name=\"t5-small\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVmeQhk6SrYp"
   },
   "outputs": [],
   "source": [
    "def chat_with_pdf(pdf_path, query):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    index, sentences = create_vector_database(text)\n",
    "\n",
    "    retrieved_context = \" \".join(retrieve_answer(query, index, sentences))\n",
    "\n",
    "    answer = generate_answer(retrieved_context, query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N9muMbXSsmZ"
   },
   "outputs": [],
   "source": [
    "pdf_path = \"file path\"\n",
    "query = \"What is the topic of this document?\"\n",
    "\n",
    "answer = chat_with_pdf(pdf_path, query)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4UFxBXjMmJN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
